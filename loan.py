# -*- coding: utf-8 -*-
"""loan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S1T8y2qZ7avZZr1fmU7judXmVjLbIbo6
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_csv("C:/Users/gamin/AppData/Local/Temp/756a2f8e-b640-4f28-87c6-c82ac187788a_archive (6).zip.88a/loan dataset.csv")

# Preview data
df.head()

# üîÅ Always work on a fresh copy to avoid SettingWithCopyWarning
df = df.copy()

# ‚úÖ Fill missing values safely (no inplace usage)
# Use mode()[0] for categorical, median or mode for numerical
df['Gender'] = df['Gender'].fillna(df['Gender'].mode()[0])
df['Dependents'] = df['Dependents'].fillna(df['Dependents'].mode()[0])
df['Self_Employed'] = df['Self_Employed'].fillna(df['Self_Employed'].mode()[0])
df['LoanAmount'] = df['LoanAmount'].fillna(df['LoanAmount'].median())
df['Loan_Amount_Term'] = df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].mode()[0])
df['Credit_History'] = df['Credit_History'].fillna(df['Credit_History'].mode()[0])

# üîª Drop Loan_ID as it's just an identifier
df = df.drop(columns=['Loan_ID'])

# ‚úÖ Confirm no missing values remain
print("Missing values after cleaning:")
print(df.isnull().sum())

# Simulate a Default_Status column (binary classification)
np.random.seed(42)
df['Default_Status'] = np.random.choice([0, 1], size=len(df), p=[0.75, 0.25])  # 0 = No default, 1 = Default

# Distribution of target
sns.countplot(x='Default_Status', data=df)
plt.title("Loan Default Status Distribution")
plt.show()

# Boxplot of income vs. default status
sns.boxplot(x='Default_Status', y='ApplicantIncome', data=df)
plt.title("Income vs Default")
plt.show()

# Credit history vs default
sns.countplot(x='Credit_History', hue='Default_Status', data=df)
plt.title("Credit History vs Default")
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Encode categorical variables
le = LabelEncoder()
categorical_cols = df.select_dtypes(include='object').columns

for col in categorical_cols:
    df[col] = le.fit_transform(df[col])

# Feature-target split
X = df.drop('Default_Status', axis=1)
y = df['Default_Status']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Random Forest model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Evaluation
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

# Apply PCA to reduce dimensions
pca = PCA(n_components=2)
pca_components = pca.fit_transform(X)

# KMeans Clustering
kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(pca_components)

# Plotting clusters
plt.figure(figsize=(8,6))
plt.scatter(pca_components[:,0], pca_components[:,1], c=clusters, cmap='viridis')
plt.title("Customer Segments (via KMeans + PCA)")
plt.xlabel("PCA 1")
plt.ylabel("PCA 2")
plt.show()

